{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "result_dir = '../AccessControl/SmartBugsWild/tool_output'\n",
    "json_file = '../AccessControl/SmartBugsWild/all_files.json'\n",
    "output_path = '../AccessControl/SmartBugsWild/parsed_tool_output/'\n",
    "\n",
    "# make dir if not exist\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "# base_dir = os.path.dirname(os.path.abspath(json_file))\n",
    "with open(json_file, 'r') as f:\n",
    "    all_files = json.load(f)\n",
    "print (len(all_files))\n",
    "tool_output_file = {\n",
    "    \"achecker\" : \"achecker_output.txt\",\n",
    "    \"sailfish\" : \"sailfish_output.txt\",\n",
    "    \"spcon\": \"spcon_output.txt\",\n",
    "    \"mythril\" : \"mythril/result.json\",\n",
    "    \"semgrep\" : \"semgrep/result.json\",\n",
    "    \"slither\" : \"slither/result.json\",\n",
    "    \"slither_raw\" : \"slither/slither_raw.json\",\n",
    "    \"gpt4\" : \"output_gpt-4-1106-preview.json\",\n",
    "    \"gpt3\" : \"output_gpt-3.5-turbo-1106.json\",\n",
    "    \"gpt3_run2\" : \"output_gpt-3.5-turbo-1106run2.json\",\n",
    "    \"gpt4_run2\" : \"output_gpt-4-1106-previewrun2.json\",\n",
    "}\n",
    "# samples:\n",
    "# spcon : CRITICAL:spcon.symExec:Permission Bug: find an attack sequence ['setOwner', 'lockBalances']\n",
    "# Achecker : Violated access control check in function freezeAccount(address,bool)\n",
    "# \t            ( 2333)  91d:\t57\t-2 +0 = -2\tJUMPI\n",
    "#               +--Attacker can make changes to AC item {0} in function owned()\n",
    "\n",
    "# mythril:  \"name\": \"Dependence on tx.origin (SWC 115)\", \"name\" : SWC 105 SWC 106\n",
    "# mythril reentrancy : State access after external call (SWC 107)\n",
    "achecker_stop_line = \"Violated access control check in\" # stop line between tx sequences\n",
    "achecker_stop_line_2 = \"Missing access control check in\"\n",
    "access_control_key_words = {\n",
    "    \"achecker\" : [\"Attacker can make changes\", \"Needed to protect following\"],\n",
    "    \"spcon\": \"CRITICAL:spcon.symExec:Permission Bug\",\n",
    "    \"mythril\" : [\"SWC 115\",\"SWC 112\", \"SWC 105\", \"SWC 106\", \"External Call To User-Supplied Address (SWC 107)\"],\n",
    "    \"semgrep\" : [\"erc20-public-transfer\", \"erc20-public-burn\", \"erc721-arbitrary-transferfrom\"\n",
    "                 , \"redacted-cartel-custom-approval-bug\", \"rigoblock-missing-access-control\",\n",
    "                 \"tecra-coin-burnfrom-bug\", \"superfluid-ctx-injection\", \"arbitrary-low-level-call\",\n",
    "                 \"proxy-storage-collision\", \"unrestricted-transferownership\", \"msg-value-multicall\",\n",
    "                 \"delegatecall-to-arbitrary-address\", \"accessible-selfdestruct\",],\n",
    "    \"slither\" : [\"arbitrary-send\",\"arbitrary-send-erc20-permit\", \"arbitrary-send-eth\", \"arbitrary-send-erc20\",\n",
    "                  \"protected-vars\", \"unprotected-upgrade\",\"suicidal\", \"controlled-delegatecall\", \"tx-origin\"],\n",
    "}\n",
    "def parse_slither_result_smartbugs(all_files, result_dir):\n",
    "    all_findings = {}\n",
    "    for key_,val_ in all_files.items():\n",
    "        file_path = val_['file']\n",
    "        result_path = os.path.join(result_dir, file_path)\n",
    "        slither_output = os.path.join(result_path, tool_output_file['slither'])\n",
    "        if not os.path.exists(slither_output):\n",
    "            continue\n",
    "        with open(slither_output, 'r') as f:\n",
    "            slither_result = json.load(f)\n",
    "            findings = slither_result['findings']\n",
    "            for finding in findings:\n",
    "                if finding['name'] in access_control_key_words['slither']:\n",
    "                    print (key_, finding.get('name'), finding.get('message'))\n",
    "                    print (finding.get('contract'), finding.get('function'), finding.get('line'), finding.get('line_end') )\n",
    "                    all_findings[key_] = finding\n",
    "    return all_findings\n",
    "def parse_slither_result(all_files, result_dir, smartbugs = False):\n",
    "    if smartbugs:\n",
    "        return parse_slither_result_smartbugs(all_files, result_dir)\n",
    "    else:\n",
    "        return parse_slither_result_raw_json(all_files, result_dir)\n",
    "\n",
    "def parse_slither_result_raw_json(all_files, result_dir):\n",
    "    all_findings = {}\n",
    "    for key_,val_ in all_files.items():\n",
    "        file_path = val_['file']\n",
    "        result_path = os.path.join(result_dir, file_path)\n",
    "        slither_output = os.path.join(result_path, tool_output_file['slither_raw'])\n",
    "        if not os.path.exists(slither_output):\n",
    "            continue\n",
    "        with open(slither_output, 'r') as f:\n",
    "            slither_result = json.load(f)\n",
    "            findings = slither_result.get('results').get('detectors')\n",
    "            if not findings:\n",
    "                continue\n",
    "            for finding in findings:\n",
    "                if finding['check'] in access_control_key_words['slither']:\n",
    "                    elements = finding.get('elements')\n",
    "                    for element in elements:\n",
    "                        if element.get('type') == 'function':\n",
    "                            source_mapping = element.get('source_mapping')\n",
    "                            function_name = element.get('name')\n",
    "                            print (key_, finding)\n",
    "                            # print (key_, finding.get('name'), finding.get('description'))\n",
    "                            # print (finding.get('contract'), finding.get('function'), finding.get('line'), finding.get('line_end') )\n",
    "                            new_finding = {\n",
    "                                \"name\": finding['check'],\n",
    "                                \"message\": finding['description'],\n",
    "                                \"function\" : function_name,\n",
    "                                # \"line\" : source_mapping.get(\"lines\")[0],\n",
    "                                # \"line_end\" : source_mapping.get(\"lines\")[-1],\n",
    "                            }\n",
    "                            all_findings[key_] = new_finding\n",
    "                            break\n",
    "    return all_findings\n",
    "\n",
    "\n",
    "def parse_semgrep_result(all_files, result_dir):\n",
    "    all_findings = {}\n",
    "    for key_, val_ in all_files.items():\n",
    "        file_path = val_['file']\n",
    "        result_path = os.path.join(result_dir, file_path)\n",
    "        semgrep_output = os.path.join(result_path, tool_output_file['semgrep'])\n",
    "        if not os.path.exists(semgrep_output):\n",
    "            continue\n",
    "        with open(semgrep_output, 'r') as f:\n",
    "            semgrep_result = json.load(f)\n",
    "            findings = semgrep_result['findings']\n",
    "            for finding in findings:\n",
    "                # print (finding['name'], finding['message'], finding['line'])\n",
    "                if finding[\"category\"] == \"security\":\n",
    "                # if finding['name'] in access_control_key_words['semgrep']:\n",
    "                    print (key_, finding.get('name'), finding.get('message'), finding.get('line'))\n",
    "                    all_findings[key_] = finding\n",
    "\n",
    "    return all_findings\n",
    "def parse_mythril_result(all_files, result_dir):\n",
    "    all_findings = {}\n",
    "    for key_, val_ in all_files.items():\n",
    "        file_path = val_['file']\n",
    "        result_path = os.path.join(result_dir, file_path)\n",
    "        mythril_output = os.path.join(result_path, tool_output_file['mythril'])\n",
    "        if not os.path.exists(mythril_output):\n",
    "            continue\n",
    "        with open(mythril_output, 'r') as f:\n",
    "            mythril_result = json.load(f)\n",
    "            findings = mythril_result['findings']\n",
    "            for finding in findings:\n",
    "                # print (finding['name'], finding['message'], finding['line'])\n",
    "                # special case for mythril as name is longer than keyword\n",
    "                for key_word in access_control_key_words['mythril']:\n",
    "                    if key_word in finding['name']:\n",
    "                        # print (key_, finding.get('name'), finding.get('message'), finding.get('function'))\n",
    "                        all_findings[key_] = finding\n",
    "\n",
    "    return all_findings\n",
    "\n",
    "\n",
    "def parse_spcon_result(all_files, result_dir):\n",
    "    all_findings = {}\n",
    "    for key_, val_ in all_files.items():\n",
    "        file_path = val_['file']\n",
    "        result_path = os.path.join(result_dir, file_path)\n",
    "        spcon_output = os.path.join(result_path, tool_output_file['spcon'])\n",
    "        if not os.path.exists(spcon_output):\n",
    "            continue\n",
    "        with open(spcon_output, 'r') as f:\n",
    "            spcon_result = f.readlines()\n",
    "            matched = False\n",
    "            for line in spcon_result:\n",
    "                if access_control_key_words['spcon'] in line:\n",
    "                    match = re.search(r\"\\['(.*?)'\\]\", line)\n",
    "                    # Parse and split the array if found\n",
    "                    array = match.group(1).split(\"', '\") if match else []\n",
    "                    matched = True\n",
    "                    print (key_, line, array[0])\n",
    "                    all_findings[key_] = {\n",
    "                        \"message\": line,\n",
    "                        \"function\" : array[0]\n",
    "                    }\n",
    "            if  not matched:\n",
    "                # print (\"not matched\", key_)\n",
    "                # print (spcon_result)\n",
    "                full_text = \"\\n\".join(spcon_result)\n",
    "                if \"INFO:spcon.symExec:test sequence timeout\" in full_text:\n",
    "                    # special case\n",
    "                    print (\"special case\")\n",
    "                    pattern = r\"INFO:spcon.symExec:Test Sequence: \\['(\\w+)'\\]\"\n",
    "                    match = re.search(pattern, full_text)\n",
    "                    # print (match)\n",
    "                    if match:\n",
    "                        function_name = match.group(1)\n",
    "                        print (key_, function_name)\n",
    "                        all_findings[key_] = {\n",
    "                            \"message\": \"Test sequence found but SymEx timeout\",\n",
    "                            \"function\" : function_name\n",
    "                        }\n",
    "\n",
    "    print (all_findings)\n",
    "    return all_findings\n",
    "def extract_achecker_function_name(line):\n",
    "    match = re.search(r\"function (\\w+)\\(.*?\\)\", line)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        # Handle the special case for fallback function\n",
    "        if \"function ()\" in line:\n",
    "            return \"fallback\"\n",
    "        # Handle the special case for 4byte function identifiers\n",
    "        elif re.search(r\"function ([0-9a-f]{8})\", line):\n",
    "            print (\"4byte function identifier found\")\n",
    "            print (f\"4byte_{line.split()[-1]}\")\n",
    "            return f\"4byte_{line.split()[-1]}\"\n",
    "        else:\n",
    "            return None\n",
    "def parse_achecker_result(all_files, result_dir):\n",
    "    all_findings = {}\n",
    "    for key_, val_ in all_files.items():\n",
    "        file_path = val_['file']\n",
    "        result_path = os.path.join(result_dir, file_path)\n",
    "        achecker_output = os.path.join(result_path, tool_output_file['achecker'])\n",
    "        if not os.path.exists(achecker_output):\n",
    "            continue\n",
    "        with open(achecker_output, 'r') as f:\n",
    "            achecker_result = f.readlines()\n",
    "            tx_sequence_buffer = []\n",
    "            message_buffer = []\n",
    "            for line in achecker_result:\n",
    "                if achecker_stop_line in line or achecker_stop_line_2 in line:\n",
    "                    tx_sequence_buffer = []\n",
    "                    message_buffer = []\n",
    "                for key_word in access_control_key_words['achecker']:\n",
    "                    if key_word in line:\n",
    "                        # Regular expression to find the function name\n",
    "                        # function_name = re.search(r\"function (\\w+)\\(.*?\\)\", line)\n",
    "                        # Extract the function name if found\n",
    "                        extracted_function_name = extract_achecker_function_name(line)\n",
    "                        tx_sequence_buffer.append(extracted_function_name)\n",
    "                        message_buffer.append(line)\n",
    "                        # print (\"extracted_function_name \",extracted_function_name)\n",
    "                        # print (key_, line, extracted_function_name)\n",
    "                if len(tx_sequence_buffer) > 0:\n",
    "                    print (key_, tx_sequence_buffer)\n",
    "                    if key_ not in all_findings:\n",
    "                        all_findings[key_] = {\n",
    "                            \"message\": message_buffer[0],\n",
    "                            \"function\" : tx_sequence_buffer[0]\n",
    "                        }\n",
    "\n",
    "    return all_findings\n",
    "def parse_gpt_result(all_files, result_dir, tool_name):\n",
    "    all_findings = {}\n",
    "    for key_, val_ in all_files.items():\n",
    "        file_path = val_['file']\n",
    "        result_path = os.path.join(result_dir, file_path)\n",
    "        gpt_result = os.path.join(result_path, tool_output_file[tool_name])\n",
    "        if not os.path.exists(gpt_result):\n",
    "            print (\"result not found \", key_)\n",
    "            continue\n",
    "\n",
    "        with open(gpt_result, 'r') as f:\n",
    "            parts = [part.split('\\n')[::-1] for part in f.read().split('\\n\\n')]\n",
    "            final_result = []\n",
    "            for part in parts:\n",
    "                lines = [line for line in part if line.strip() and line != \"```\"]\n",
    "                if len(lines) < 2:\n",
    "                    continue\n",
    "\n",
    "                if re.match(r'\\d+\\..*', lines[1]): # treat as patten: 1. fname\\n - message ...\n",
    "                    for msg_fname in [lines[i:i + 2] for i in range(0, len(lines), 2)]:\n",
    "                        if len(msg_fname) < 2:\n",
    "                            print('ignore', msg_fname)\n",
    "                            continue\n",
    "                        msg, fname = msg_fname\n",
    "                        fname=fname.split('.')[-1].strip()\n",
    "                        final_result.append(dict(function=fname, message=msg))\n",
    "                    continue\n",
    "\n",
    "                # treat as pattern: fname\\n\\fname\\n message ...\n",
    "                message = lines[0]\n",
    "                functions = lines[1:]\n",
    "                for function in functions:\n",
    "                    fname = [name.strip('''\"'`''') for name in function.split() if name.lower()!='the' and name !='function'][0]\n",
    "                    final_result.append(dict(function=fname, message=message))\n",
    "            if len(final_result) > 0:\n",
    "                all_findings[key_] = final_result\n",
    "    return all_findings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_tool(tool_name, all_files, result_dir):\n",
    "    if tool_name == \"slither\":\n",
    "        return parse_slither_result(all_files, result_dir)\n",
    "    elif tool_name == \"semgrep\":\n",
    "        return parse_semgrep_result(all_files, result_dir)\n",
    "    elif tool_name == \"mythril\":\n",
    "        return parse_mythril_result(all_files, result_dir)\n",
    "    elif tool_name == \"spcon\":\n",
    "        return parse_spcon_result(all_files, result_dir)\n",
    "    elif tool_name == \"achecker\":\n",
    "        return parse_achecker_result(all_files, result_dir)\n",
    "    elif \"gpt\" in tool_name:\n",
    "        return parse_gpt_result(all_files, result_dir, tool_name)\n",
    "    else:\n",
    "        print (\"Tool name not found\")\n",
    "        return None\n",
    "# all_tools = [\"slither\", \"semgrep\", \"mythril\", \"spcon\", \"achecker\"]\n",
    "all_tools = [\"gpt3\"]\n",
    "# all_tools = [ \"achecker\"]\n",
    "for tool in all_tools:\n",
    "    res = parse_tool(tool, all_files, result_dir)\n",
    "    all_addresses = {}\n",
    "    print (\"Processing tool \", tool, len(res))\n",
    "    print (output_path +tool + \"_addresses.json\")\n",
    "    for key_, val_ in res.items():\n",
    "        # print (key_, val_['function'], val_['message'])\n",
    "        # all_files[key_.split(\"/\")[0]]['tool'] = tool\n",
    "        print (key_)\n",
    "        all_addresses[key_] = []\n",
    "        if type(val_) == list:\n",
    "            for finding in val_:\n",
    "                all_addresses[key_].append({\n",
    "                    \"location\": finding['function'].split(\"(\")[0],\n",
    "                    \"message\": finding['message']\n",
    "                })\n",
    "        else:\n",
    "            if \"function\" not in val_:\n",
    "                all_addresses[key_].append({\n",
    "                    \"location\": val_['line'],\n",
    "                    \"message\": val_['message']\n",
    "                })\n",
    "            else:\n",
    "                all_addresses[key_].append({\n",
    "                    \"location\": val_['function'].split(\"(\")[0],\n",
    "                    \"message\": val_['message']\n",
    "                })\n",
    "        # if tool == \"semgrep\":\n",
    "        #     all_addresses[key_][\"location\"] = val_['line']\n",
    "        # else:\n",
    "        #     print (key_, val_['function'], val_['message'])\n",
    "        #     all_addresses[key_][\"location\"] = val_['function'].split(\"(\")[0]\n",
    "        # all_addresses[key_][\"message\"] = val_['message']\n",
    "    json.dump(all_addresses, open(output_path +tool + \"_addresses.json\", 'w'), indent=2)\n",
    "\n",
    "\n",
    "\n",
    "parse_slither_result(all_files, result_dir)\n",
    "parse_semgrep_result(all_files, result_dir)\n",
    "parse_mythril_result(all_files, result_dir)\n",
    "parse_spcon_result(all_files, result_dir)\n",
    "parse_achecker_result(all_files, result_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post process achecker 4byte to function name\n",
    "tool = \"achecker\"\n",
    "achecker_res_file = output_path +tool + \"_addresses.json\"\n",
    "achecker_res = json.load(open(achecker_res_file, 'r'))\n",
    "from eth_utils import function_abi_to_4byte_selector\n",
    "base_dir = '../AccessControl/SmartBugsWild/contracts/'\n",
    "for key_, val_ in achecker_res.items():\n",
    "    if \"4byte_\" in val_[\"location\"]:\n",
    "        print (key_, val_)\n",
    "        file_path = base_dir + key_\n",
    "        # find .abi file in file_path\n",
    "        for file in os.listdir(file_path):\n",
    "            if file.endswith('.abi'):\n",
    "                contract_abi_file = os.path.join(file_path, file)\n",
    "                contract_abi = json.load(open(contract_abi_file, 'r'))\n",
    "                for func in contract_abi:\n",
    "                    # print (func)\n",
    "                    if func.get(\"type\") != \"function\":\n",
    "                        continue\n",
    "                    print (function_abi_to_4byte_selector(func).hex() )\n",
    "                    if function_abi_to_4byte_selector(func).hex() == val_[\"location\"].split(\"_\")[-1]:\n",
    "                        print (func)\n",
    "                        val_[\"location\"] = func[\"name\"]\n",
    "                        break\n",
    "\n",
    "# print (achecker_res)\n",
    "json.dump(achecker_res, open(achecker_res_file, 'w'), indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output_path = '../AccessControl/SmartBugsWild/parsed_tool_output/'\n",
    "all_fp_file = 'fp_data/all_fp.txt'\n",
    "all_tp_file = 'fp_data/all_tp.txt'\n",
    "with open(all_tp_file, 'r') as f:\n",
    "    all_tp = f.readlines()\n",
    "all_tp = [x.strip() for x in all_tp]\n",
    "print (len(all_tp))\n",
    "with open(all_fp_file, 'r') as f:\n",
    "    all_fp = f.readlines()\n",
    "all_fp = [x.strip() for x in all_fp]\n",
    "print (len(all_fp))\n",
    "tools = [\"slither\", \"semgrep\", \"mythril\", \"spcon\", \"achecker\"]\n",
    "combined_res = {}\n",
    "for tool in tools:\n",
    "    res_file = output_path +tool + \"_addresses.json\"\n",
    "    res = json.load(open(res_file, 'r'))\n",
    "    for key_, val_ in res.items():\n",
    "        if key_ not in combined_res:\n",
    "            combined_res[key_] = []\n",
    "        combined_res[key_].append({\n",
    "            \"tool\": tool,\n",
    "            \"location\": val_.get('location'),\n",
    "            \"message\" : val_.get('message')\n",
    "            })\n",
    "print (combined_res)\n",
    "print (len(combined_res))\n",
    "json.dump(combined_res, open(output_path + \"combined_res_all_tool.json\", 'w'), indent=2)\n",
    "with open(output_path + \"combined_res_simplified.csv\", 'w') as f:\n",
    "    for key_, val_ in combined_res.items():\n",
    "        # item = val_[0]\n",
    "        tool = ':'.join([x['tool'] for x in val_])\n",
    "        location = ':'.join([str(x['location']) for x in val_])\n",
    "        false_positive = key_ in all_fp\n",
    "        true_positive = key_ in all_tp\n",
    "        f.write(f\"{key_},{tool},{location},{true_positive},{false_positive}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
